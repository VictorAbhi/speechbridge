{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO1jyfA15MNhcawL22Zxdhy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6f1d60ee6d8c4d888adf4fbb0a52feb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c0e694190f442fc981cf1861538838a","IPY_MODEL_497f791a31464b8ab45fcf1bcd538b6e","IPY_MODEL_f0ddb3df3f0d423c931e385af27ecf8d"],"layout":"IPY_MODEL_9d6ca655905e471fa0899f53fe8b1719"}},"5c0e694190f442fc981cf1861538838a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de894f8b1ca244d0bf2959a4cd6b5a3c","placeholder":"​","style":"IPY_MODEL_1813ee4fc2a84423aa5682fa7a5b2083","value":"Map:   0%"}},"497f791a31464b8ab45fcf1bcd538b6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5eb8a230f8314ddd8a824bff02ad362e","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74e4c5f768534458be52b8fee6674b1e","value":0}},"f0ddb3df3f0d423c931e385af27ecf8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82fa641c616c4aae89125579000cadbf","placeholder":"​","style":"IPY_MODEL_5d456f1efc5d43cfb325c91bc692d12d","value":" 0/1000 [00:00&lt;?, ? examples/s]"}},"9d6ca655905e471fa0899f53fe8b1719":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de894f8b1ca244d0bf2959a4cd6b5a3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1813ee4fc2a84423aa5682fa7a5b2083":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5eb8a230f8314ddd8a824bff02ad362e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74e4c5f768534458be52b8fee6674b1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82fa641c616c4aae89125579000cadbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d456f1efc5d43cfb325c91bc692d12d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc5e01b957bb4f1fad124e1b307cf453":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebef4a1a3c9e45c4ac693b3299fa3adc","IPY_MODEL_8e79df8e26504be09e61c7bf6924f167","IPY_MODEL_0c3b97a758a5408da97a94ff25fc519b"],"layout":"IPY_MODEL_b1d679eaf5994c0f97715f26ea1515a0"}},"ebef4a1a3c9e45c4ac693b3299fa3adc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50c28fb78f1247d9a6b3e8a086c33d80","placeholder":"​","style":"IPY_MODEL_b43d8a40643145f280e0a9264e630f4a","value":"Downloading readme: 100%"}},"8e79df8e26504be09e61c7bf6924f167":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_899542b623904f4cb90372b96bb2cb35","max":2280,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb2e6938942f4e26a532f4f42486499c","value":2280}},"0c3b97a758a5408da97a94ff25fc519b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae3f26348be24ec681a392ef40e4f6fa","placeholder":"​","style":"IPY_MODEL_33bbf3d2ab15483fb7536c505685477c","value":" 2.28k/2.28k [00:00&lt;00:00, 11.6kB/s]"}},"b1d679eaf5994c0f97715f26ea1515a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50c28fb78f1247d9a6b3e8a086c33d80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b43d8a40643145f280e0a9264e630f4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"899542b623904f4cb90372b96bb2cb35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb2e6938942f4e26a532f4f42486499c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae3f26348be24ec681a392ef40e4f6fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33bbf3d2ab15483fb7536c505685477c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xmxdvW1puywF","executionInfo":{"status":"ok","timestamp":1761712526271,"user_tz":420,"elapsed":21525,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"81be4b6b-249f-4094-8921-9de97f44113e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"ishworsubedii/nepali-speech-to-text-dataset\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFhoxxZ1vT95","executionInfo":{"status":"ok","timestamp":1761704786025,"user_tz":-345,"elapsed":41481,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"fb463e85-7c98-4e27-f11f-36e8ebd5bc92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/ishworsubedii/nepali-speech-to-text-dataset?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.01G/1.01G [00:09<00:00, 119MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/ishworsubedii/nepali-speech-to-text-dataset/versions/1\n"]}]},{"cell_type":"code","source":["!mv /root/.cache/kagglehub/datasets/ishworsubedii/nepali-speech-to-text-dataset/versions/1 /content/drive/MyDrive"],"metadata":{"id":"QETHe6UHwgfN"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1f74d819","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761709112606,"user_tz":420,"elapsed":219,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"f3262a6f-59db-406a-e995-a73c4281d909"},"source":["!wget https://huggingface.co/datasets/spktsagar/openslr-nepali-asr-cleaned/resolve/main/openslr-nepali-asr-cleaned.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Could not load dataset directly: Dataset scripts are no longer supported, but found openslr-nepali-asr-cleaned.py\n","Attempting to load from local path if available...\n"]}]},{"cell_type":"code","source":["!pip install -q datasets accelerate peft bitsandbytes jiwer evaluate librosa soundfile\n"],"metadata":{"id":"fBRYkbvbHfJo","executionInfo":{"status":"ok","timestamp":1761719139324,"user_tz":420,"elapsed":21270,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset, concatenate_datasets\n","\n","nepali = load_dataset(\"amitpant7/nepali-speech-to-text\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ca1tExzvHjDP","executionInfo":{"status":"ok","timestamp":1761713935126,"user_tz":420,"elapsed":1332,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"a095c3e1-cc11-4681-b698-c47705462725"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"]}]},{"cell_type":"code","source":["from transformers import WhisperProcessor\n","\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"multilingual\", task=\"transcribe\")\n","\n","def prepare(example):\n","    audio = example[\"audio\"]\n","    example[\"input_features\"] = processor(audio[\"array\"], sampling_rate=16000).input_features[0]\n","    example[\"labels\"] = processor.tokenizer(example[\"transcription\"]).input_ids # Corrected from example[\"sentence\"]\n","    return example\n","\n","dataset = nepali.map(prepare, remove_columns=['audio', 'transcription'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["6f1d60ee6d8c4d888adf4fbb0a52feb0","5c0e694190f442fc981cf1861538838a","497f791a31464b8ab45fcf1bcd538b6e","f0ddb3df3f0d423c931e385af27ecf8d","9d6ca655905e471fa0899f53fe8b1719","de894f8b1ca244d0bf2959a4cd6b5a3c","1813ee4fc2a84423aa5682fa7a5b2083","5eb8a230f8314ddd8a824bff02ad362e","74e4c5f768534458be52b8fee6674b1e","82fa641c616c4aae89125579000cadbf","5d456f1efc5d43cfb325c91bc692d12d"]},"id":"x_St7fcuOEs1","outputId":"5644a137-5e35-4f39-ca94-c9ad8eddab93"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f1d60ee6d8c4d888adf4fbb0a52feb0"}},"metadata":{}}]},{"cell_type":"code","source":["!apt-get update && apt-get install -y ffmpeg  # Fix for TorchCodec/FFmpeg issues\n","!pip install -q datasets==2.21.0 accelerate peft bitsandbytes jiwer evaluate librosa soundfile transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhv_fu9zUgZK","executionInfo":{"status":"ok","timestamp":1761714318755,"user_tz":420,"elapsed":14664,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"b366eeb4-aac8-4dad-9d93-742cefaa3784"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Hit:2 https://cli.github.com/packages stable InRelease\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,086 kB]\n","Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,827 kB]\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,418 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,479 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,070 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,878 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,288 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,807 kB]\n","Fetched 36.8 MB in 4s (9,993 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from datasets import load_dataset, concatenate_datasets\n","\n","# Load the dataset (it has multiple 'train.*' splits)\n","nepali = load_dataset(\"amitpant7/nepali-speech-to-text\")\n","\n","# Concatenate all train splits (ignore any test if present)\n","train_splits = [split for split in nepali if 'train' in split]\n","nepali_train = concatenate_datasets([nepali[split] for split in train_splits])\n","\n","print(f\"Loaded {len(nepali_train)} training samples.\")\n","print(nepali_train)\n","print(nepali_train[0])  # Preview one example"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329,"referenced_widgets":["fc5e01b957bb4f1fad124e1b307cf453","ebef4a1a3c9e45c4ac693b3299fa3adc","8e79df8e26504be09e61c7bf6924f167","0c3b97a758a5408da97a94ff25fc519b","b1d679eaf5994c0f97715f26ea1515a0","50c28fb78f1247d9a6b3e8a086c33d80","b43d8a40643145f280e0a9264e630f4a","899542b623904f4cb90372b96bb2cb35","eb2e6938942f4e26a532f4f42486499c","ae3f26348be24ec681a392ef40e4f6fa","33bbf3d2ab15483fb7536c505685477c"]},"id":"DzRauGM-VMJx","executionInfo":{"status":"ok","timestamp":1761714364836,"user_tz":420,"elapsed":20312,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"a6b7ed21-9e89-4a7b-e7f5-87ba8483ee29"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/2.28k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc5e01b957bb4f1fad124e1b307cf453"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded 2650 training samples.\n","Dataset({\n","    features: ['audio', 'transcription'],\n","    num_rows: 2650\n","})\n","{'audio': {'path': 'train_audio_0.wav', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n","        2.60547258e-05,  8.18362423e-06, -4.72624306e-05]), 'sampling_rate': 32000}, 'transcription': 'म पनि जान्छु है त अहिले लाई ।'}\n"]}]},{"cell_type":"code","source":["from transformers import WhisperProcessor\n","import torch\n","\n","# Load processor with Nepali language\n","processor = WhisperProcessor.from_pretrained(\n","    \"openai/whisper-small\",\n","    language=\"ne\",\n","    task=\"transcribe\"\n",")\n","\n","def prepare(example):\n","    audio = example[\"audio\"]\n","    # Resample audio to 16000 Hz\n","    audio = audio.copy_resample(16000)\n","    # Use actual sampling rate for resampling; return PyTorch tensors\n","    example[\"input_features\"] = processor(\n","        audio[\"array\"],\n","        sampling_rate=audio[\"sampling_rate\"],\n","        return_tensors=\"pt\"\n","    ).input_features[0]\n","\n","    # Encode transcription to labels\n","    example[\"labels\"] = processor.tokenizer(example[\"transcription\"]).input_ids\n","    return example\n","\n","# Map safely: single process, non-batched to avoid OOM\n","nepali_train = nepali_train.map(\n","    prepare,\n","    remove_columns=nepali_train.column_names,  # Clean up after processing\n","    num_proc=1,\n","    batched=False\n",")\n","\n","# Optional: Add a simple validation split (10% of train)\n","nepali_train = nepali_train.train_test_split(test_size=0.1, shuffle=True)\n","print(\"Processed dataset splits:\", nepali_train)\n","\n","# Save to disk if needed (for resuming)\n","nepali_train.save_to_disk(\"/content/drive/MyDrive/nepali_whisper_processed\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"collapsed":true,"id":"yqltcelCW5Dv","executionInfo":{"status":"error","timestamp":1761715434449,"user_tz":420,"elapsed":1152,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"41642d2f-55b0-4e90-c2e9-615c36c72881"},"execution_count":15,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Column to remove ['train', 'test'] not in the dataset. Current columns in the dataset: ['input_features', 'labels']","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2193564857.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Map safely: single process, non-batched to avoid OOM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m nepali_train = nepali_train.map(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mremove_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnepali_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Clean up after processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    868\u001b[0m         return DatasetDict(\n\u001b[1;32m    869\u001b[0m             {\n\u001b[0;32m--> 870\u001b[0;31m                 k: dataset.map(\n\u001b[0m\u001b[1;32m    871\u001b[0m                     \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         }\n\u001b[1;32m    566\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3085\u001b[0m             \u001b[0mmissing_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3086\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3087\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   3088\u001b[0m                     \u001b[0;34mf\"Column to remove {list(missing_columns)} not in the dataset. Current columns in the dataset: {self._data.column_names}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m                 )\n","\u001b[0;31mValueError\u001b[0m: Column to remove ['train', 'test'] not in the dataset. Current columns in the dataset: ['input_features', 'labels']"]}]},{"cell_type":"code","source":["!pip install --upgrade transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oyyWAMhaQrw","executionInfo":{"status":"ok","timestamp":1761715239270,"user_tz":420,"elapsed":6823,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"41be251b-ef74-43a6-c4c0-3290a2dde17a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"]}]},{"cell_type":"code","source":["from datasets import load_from_disk\n","import torch\n","from transformers import WhisperProcessor\n","from peft import LoraConfig, get_peft_model, TaskType\n","\n","# Load saved dataset (includes train/test splits)\n","nepali_train = load_from_disk(\"/content/drive/MyDrive/nepali_whisper_processed\")\n","print(\"Loaded dataset:\", nepali_train)\n","print(f\"Train samples: {len(nepali_train['train'])}, Eval samples: {len(nepali_train['test'])}\")\n","\n","# Reload processor (for collator and metrics)\n","processor = WhisperProcessor.from_pretrained(\n","    \"openai/whisper-small\",\n","    language=\"ne\",\n","    task=\"transcribe\"\n",")\n","\n","# Your compute_metrics function (from previous cell)\n","import evaluate\n","wer_metric = evaluate.load(\"wer\")\n","\n","def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    # replace -100 with the pad_token_id\n","    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n","\n","    # we do not want to group tokens when computing the metrics\n","    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yAqGt9qHdqk_","executionInfo":{"status":"ok","timestamp":1761719142496,"user_tz":420,"elapsed":3169,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"660211f6-ad00-4639-9ac0-b9ca66c49e80"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded dataset: DatasetDict({\n","    train: Dataset({\n","        features: ['input_features', 'labels'],\n","        num_rows: 2385\n","    })\n","    test: Dataset({\n","        features: ['input_features', 'labels'],\n","        num_rows: 265\n","    })\n","})\n","Train samples: 2385, Eval samples: 265\n"]}]},{"cell_type":"code","source":["import torch\n","from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","\n","from transformers import (\n","    WhisperProcessor,\n","    WhisperForConditionalGeneration,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer\n",")\n","from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n","\n","# -----------------------------\n","# CORRECTED Data collator for Whisper\n","# -----------------------------\n","@dataclass\n","class DataCollatorSpeechSeq2SeqWithPadding:\n","    processor: Any\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # input_features already processed, just stack them\n","        input_features = [torch.tensor(f[\"input_features\"]) for f in features]\n","\n","        # Pad input features to same length\n","        input_features = torch.nn.utils.rnn.pad_sequence(\n","            input_features, batch_first=True, padding_value=0.0\n","        )\n","\n","        # Handle labels\n","        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        batch = {\n","            \"input_features\": input_features,\n","            \"labels\": labels,\n","        }\n","        return batch\n","\n","# -----------------------------\n","# Training parameters\n","# -----------------------------\n","model_id = \"small\"\n","task = \"transcribe\"\n","language = \"ne\"\n","\n","# LoRA parameters\n","r = 16\n","lora_alpha = 32\n","lora_dropout = 0.1\n","\n","# Training parameters\n","learning_rate = 1e-4\n","train_batch_size = 8  # Reduced to avoid memory issues\n","gradient_accumulation_steps = 2\n","fp16 = True\n","warmup_steps = 100\n","max_steps = 1000\n","save_steps = 200\n","logging_steps = 50\n","\n","experiment_name = f\"whisper-{model_id}-lora-nepali\"\n","\n","# -----------------------------\n","# Load processor and model\n","# -----------------------------\n","processor = WhisperProcessor.from_pretrained(\n","    f\"openai/whisper-{model_id}\",\n","    language=language,\n","    task=task\n",")\n","\n","# Load model\n","model = WhisperForConditionalGeneration.from_pretrained(\n","    f\"openai/whisper-{model_id}\",\n","    device_map=\"auto\"\n",")\n","\n","# Configure model\n","model.config.forced_decoder_ids = None\n","model.config.suppress_tokens = []\n","model.config.use_cache = False\n","model.gradient_checkpointing_enable()\n","\n","# -----------------------------\n","# Apply LoRA\n","# -----------------------------\n","peft_config = LoraConfig(\n","    r=r,\n","    lora_alpha=lora_alpha,\n","    target_modules=[\"q_proj\", \"v_proj\"],\n","    lora_dropout=lora_dropout,\n","    bias=\"none\",\n",")\n","\n","model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()\n","\n","# -----------------------------\n","# Data collator\n","# -----------------------------\n","data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n","\n","# -----------------------------\n","# Training arguments\n","# -----------------------------\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=f\"/content/drive/MyDrive/{experiment_name}\",\n","    per_device_train_batch_size=train_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    learning_rate=learning_rate,\n","    warmup_steps=warmup_steps,\n","    max_steps=max_steps,\n","    save_steps=save_steps,\n","    logging_steps=logging_steps,\n","    eval_steps=200,\n","    save_total_limit=3,\n","    predict_with_generate=True,\n","    generation_max_length=225,\n","    report_to=[\"tensorboard\"],\n","    remove_unused_columns=False,\n","    fp16=fp16,\n",")\n","\n","# -----------------------------\n","# Trainer\n","# -----------------------------\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=nepali_train[\"train\"],\n","    eval_dataset=nepali_train[\"test\"],\n","    data_collator=data_collator,\n","    tokenizer=processor.feature_extractor,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Start training\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"XG50a3K2m0My","executionInfo":{"status":"ok","timestamp":1761722930317,"user_tz":420,"elapsed":3463858,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"b417a4e2-dc7c-4d17-ea67-f75a0fc2c1a6"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2157445051.py:128: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n","  trainer = Seq2SeqTrainer(\n","The model is already on multiple devices. Skipping the move to device specified in `args`.\n"]},{"output_type":"stream","name":"stdout","text":["trainable params: 1,769,472 || all params: 243,504,384 || trainable%: 0.7267\n"]},{"output_type":"stream","name":"stderr","text":["You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 57:14, Epoch 6/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>2.373200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.405700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.033900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.932300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.862900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.855600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.781700</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.750900</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.714600</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.612200</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.509800</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.491000</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.468500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.465000</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.461300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.445600</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.437300</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.440700</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.426300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.440300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1000, training_loss=0.7454318752288819, metrics={'train_runtime': 3440.5565, 'train_samples_per_second': 4.65, 'train_steps_per_second': 0.291, 'total_flos': 4.6319330304e+18, 'train_loss': 0.7454318752288819, 'epoch': 6.668896321070234})"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"f84256fc","executionInfo":{"status":"ok","timestamp":1761722976672,"user_tz":420,"elapsed":466,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}}},"source":["import evaluate\n","import torch\n","\n","wer_metric = evaluate.load(\"wer\")\n","\n","def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    # replace -100 with the pad_token_id\n","    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n","\n","    # we do not want to group tokens when computing the metrics\n","    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}"],"execution_count":50,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration\n","from datasets import load_from_disk\n","import evaluate\n","\n","# Load the dataset and model\n","nepali_train = load_from_disk(\"/content/drive/MyDrive/nepali_whisper_processed\")\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"ne\", task=\"transcribe\")\n","\n","# Load your trained model (use the latest checkpoint)\n","model_path = f\"/content/drive/MyDrive/whisper-small-lora-nepali/checkpoint-1000\"  # or specific checkpoint\n","model = WhisperForConditionalGeneration.from_pretrained(model_path)\n","model.eval()\n","\n","# Load WER metric\n","wer_metric = evaluate.load(\"wer\")\n","\n","def predict_and_compare(model, processor, dataset, num_samples=10):\n","    \"\"\"Compare model predictions with ground truth\"\"\"\n","\n","    results = []\n","    wer_scores = []\n","\n","    # Get random samples from test set\n","    test_dataset = dataset[\"test\"]\n","    indices = np.random.choice(len(test_dataset), min(num_samples, len(test_dataset)), replace=False)\n","\n","    print(\" Comparing Predictions vs Ground Truth:\\n\")\n","    print(\"=\" * 100)\n","\n","    for i, idx in enumerate(indices):\n","        # Convert numpy index to standard integer\n","        sample = test_dataset[int(idx)]\n","\n","        # Get input features\n","        input_features = torch.tensor(sample[\"input_features\"]).unsqueeze(0)\n","\n","        # Generate prediction\n","        with torch.no_grad():\n","            predicted_ids = model.generate(input_features, max_length=225)\n","\n","        # Decode predictions and labels\n","        prediction = processor.tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n","\n","        # Get ground truth (remove -100 padding)\n","        label_ids = sample[\"labels\"]\n","        label_ids = [token_id for token_id in label_ids if token_id != -100]\n","        ground_truth = processor.tokenizer.decode(label_ids, skip_special_tokens=True)\n","\n","        # Calculate WER for this sample\n","        wer = wer_metric.compute(predictions=[prediction], references=[ground_truth])\n","        wer_scores.append(wer)\n","\n","        results.append({\n","            'prediction': prediction,\n","            'ground_truth': ground_truth,\n","            'wer': wer\n","        })\n","\n","        # Print comparison\n","        print(f\"Sample {i+1}:\")\n","        print(f\"Ground Truth: {ground_truth}\")\n","        print(f\"Prediction:   {prediction}\")\n","        print(f\"WER: {wer:.2%}\")\n","        print(\"-\" * 80)\n","\n","    # Overall statistics\n","    avg_wer = np.mean(wer_scores)\n","    print(f\"\\nOverall Average WER: {avg_wer:.2%}\")\n","    print(f\"WER Range: {np.min(wer_scores):.2%} - {np.max(wer_scores):.2%}\")\n","\n","    return results, wer_scores\n","\n","# Run prediction comparison\n","results, wer_scores = predict_and_compare(model, processor, nepali_train, num_samples=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYXR_LotZG_z","executionInfo":{"status":"ok","timestamp":1761723373899,"user_tz":420,"elapsed":200887,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"4b80d6f0-1817-4549-a122-a99aad26baec"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n","Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"]},{"output_type":"stream","name":"stdout","text":[" Comparing Predictions vs Ground Truth:\n","\n","====================================================================================================\n"]},{"output_type":"stream","name":"stderr","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":["Sample 1:\n","Ground Truth: साथी तिमी बेनी बजार गएको छौ?\n","Prediction:   साति तिमी बेनी बजार गयागो छुु ।\n","WER: 66.67%\n","--------------------------------------------------------------------------------\n","Sample 2:\n","Ground Truth: काम र पढाइले गर्दा नै हो धेरै त ।\n","Prediction:    काम्रा पडाँ ब्राँ ब्राँ ब्राँ ग्र्दा नेँ बुदिरिता ।\n","WER: 88.89%\n","--------------------------------------------------------------------------------\n","Sample 3:\n","Ground Truth: अनाज अन्न र ओरिजा सातिभाको बीउ\n","Prediction:   अनाज अन्न्ड र उरिजा सातिबहाको व्यु\n","WER: 66.67%\n","--------------------------------------------------------------------------------\n","Sample 4:\n","Ground Truth: पोखरा त नेपालकै सफा सहर हो नि,सायद धुलो कम नै होला ।\n","Prediction:   पुख्रात नेपालके सफा सहरहो नि साया दुलुकम्ने अला ।\n","WER: 83.33%\n","--------------------------------------------------------------------------------\n","Sample 5:\n","Ground Truth: सोडियम क्लोराइडको खनिज अवस्था\n","Prediction:   सोडियम क्लोराइटको खानिज अब्ष्टा\n","WER: 75.00%\n","--------------------------------------------------------------------------------\n","Sample 6:\n","Ground Truth: उपसाला नगरमालर पोखरीको जलयातायातयोग्य एउटा शाखाको तटमा जसको नाम फैरिस नदी हो र स्टकहोम नगरको एकचालिस मिल उत्तरतिर अवस्थित छ\n","Prediction:   ौपसाला नगरमालर पोखरीको जल्लियातायात योग्य एउटा साखाको तट्टमा चस्को नाम फैरिस नदिहो र स्ट्र्क हुम्नगरको एक चालिस मिल उत्तर्तिर अवस्थित छ\n","WER: 65.00%\n","--------------------------------------------------------------------------------\n","Sample 7:\n","Ground Truth: विश्व विषयक मन्त्रीस्तरीय अन्तर्राष्ट्रिय सम्मेलनमा भाग लिन बङ्लादेशको राजधानी ढाका प्रस्थान गर्नुअघि त्रिभुवन अन्तराष्ट्रिय विमानस्थलमा सञ्चारकर्मी बिच उनले सो कुरा बताए\n","Prediction:   बिस्व बिस्व एक मन्त्रिस्टर्य अन्द्रास्ट्य समेलनमा भाग लिन बाग्रादेस्को राज्दानी डाका प्रस्थान गर्नो अगी त्रिबुवन र अन्द्रास्ट्य बिवानिस्टालमा सन्चार कर्मी बिज उन्ले सोक्कुरा बताए\n","WER: 95.24%\n","--------------------------------------------------------------------------------\n","Sample 8:\n","Ground Truth: एक्सप्रेस स्क्रिप्ट्स होल्डिङ एउटा औषधि कम्पनी हो\n","Prediction:   एक्स्प्र्स ग्रिब्स फोल्लिङ एउटा उसदी कम्पनी हो\n","WER: 57.14%\n","--------------------------------------------------------------------------------\n","Sample 9:\n","Ground Truth: भारतको पश्चिम बङ्गाल राज्यमा रहेको सहर\n","Prediction:   पार्द्टको पच्चिम बङ्गाल राजेमा रहेको सहर\n","WER: 50.00%\n","--------------------------------------------------------------------------------\n","Sample 10:\n","Ground Truth: गाह्रो प्रश्न सोध्नु भयो दाई ।\n","Prediction:   गारो प्र्श्मे सण्नुबाधाइ।\n","WER: 100.00%\n","--------------------------------------------------------------------------------\n","\n","Overall Average WER: 74.79%\n","WER Range: 50.00% - 100.00%\n"]}]},{"cell_type":"markdown","source":["Original model before finetuning"],"metadata":{"id":"PslcZlxf5M-g"}},{"cell_type":"code","source":["import evaluate\n","import torch\n","import numpy as np # Import numpy\n","\n","wer_metric = evaluate.load(\"wer\")\n","\n","def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    # replace -100 with the pad_token_id\n","    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n","\n","    # we do not want to group tokens when computing the metrics\n","    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}\n","\n","def compare_with_base_model(num_samples=5):\n","    \"\"\"Compare your fine-tuned model with the base Whisper model\"\"\"\n","\n","    # Load base model\n","    base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n","    base_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n","    base_model.eval()\n","\n","    test_dataset = nepali_train[\"test\"]\n","    indices = np.random.choice(len(test_dataset), min(num_samples, len(test_dataset)), replace=False)\n","\n","    print(\" Comparison: Fine-tuned vs Base Model\")\n","    print(\"=\" * 100)\n","\n","    for i, idx in enumerate(indices):\n","        # Convert numpy index to standard integer\n","        sample = test_dataset[int(idx)] # Corrected here\n","        input_features = torch.tensor(sample[\"input_features\"]).unsqueeze(0)\n","\n","        # Your fine-tuned model prediction\n","        with torch.no_grad():\n","            fine_tuned_pred = model.generate(input_features, max_length=225)\n","        ft_prediction = processor.tokenizer.decode(fine_tuned_pred[0], skip_special_tokens=True)\n","\n","        # Base model prediction\n","        with torch.no_grad():\n","            base_pred = base_model.generate(input_features, max_length=225)\n","        base_prediction = base_processor.tokenizer.decode(base_pred[0], skip_special_tokens=True)\n","\n","        # Ground truth\n","        label_ids = sample[\"labels\"]\n","        label_ids = [token_id for token_id in label_ids if token_id != -100]\n","        ground_truth = processor.tokenizer.decode(label_ids, skip_special_tokens=True)\n","\n","        # Calculate WER\n","        ft_wer = wer_metric.compute(predictions=[ft_prediction], references=[ground_truth])\n","        base_wer = wer_metric.compute(predictions=[base_prediction], references=[ground_truth])\n","\n","        print(f\"Sample {i+1}:\")\n","        print(f\"Ground Truth: {ground_truth}\")\n","        print(f\"Fine-tuned:   {ft_prediction} (WER: {ft_wer:.2%})\")\n","        print(f\"Base Model:   {base_prediction} (WER: {base_wer:.2%})\")\n","        # Avoid division by zero if base_wer is 0\n","        improvement = ((base_wer - ft_wer) / base_wer * 100) if base_wer != 0 else float('inf')\n","        print(f\"Improvement:  {improvement:+.1f}%\")\n","        print(\"-\" * 80)\n","\n","# Uncomment to run comparison\n","compare_with_base_model(num_samples=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRva-EK64Xwm","executionInfo":{"status":"ok","timestamp":1761723576387,"user_tz":420,"elapsed":134657,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"b2b5ecd1-3b1d-40a9-c5e7-cd4243b00c7b"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":[" Comparison: Fine-tuned vs Base Model\n","====================================================================================================\n","Sample 1:\n","Ground Truth: यो गाउँको सिमाना पातेमेला जामनेपानी छाम कर्णाली नदीसँग जोडिएको छ\n","Fine-tuned:   यो गएउगाउँगो सिमाना पाटे मेला जामणे पानि चाम् कर्नाली नदी सग्दिएको छ (WER: 90.00%)\n","Base Model:    यो गवको शिमाना पाते मेला जामने पानी चाम करनाली नदी संगा जोडी एको चाए. (WER: 130.00%)\n","Improvement:  +30.8%\n","--------------------------------------------------------------------------------\n","Sample 2:\n","Ground Truth: उहाँलाई चमत्कारिक व्यक्तित्वको रूपमा लिने गरिन्छ\n","Fine-tuned:   वाहालाई चम्ब्ट कारिक बेक्तिक्तोको रूपमा लिने गरिन्छ (WER: 66.67%)\n","Base Model:    वहा ले चवमत करिक बेक्तिख तोको रुप माल दिने गरिन सा. (WER: 183.33%)\n","Improvement:  +63.6%\n","--------------------------------------------------------------------------------\n","Sample 3:\n","Ground Truth: वालग्रिन डट् कम् यसको सुरुवातका वर्षमै प्रगतिको बाटामा लागेको थियो\n","Fine-tuned:   वाल्ग्रिन्ड ड्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट् (WER: 100.00%)\n","Base Model:    वाल्ग्रिन डड्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्ट्� (WER: 100.00%)\n","Improvement:  +0.0%\n","--------------------------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["For enlish language"],"metadata":{"id":"Ntbjyo726NBW"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration\n","\n","# Load your fine-tuned model\n","model_path = f\"/content/drive/MyDrive/whisper-small-lora-nepali/checkpoint-1000\"\n","model = WhisperForConditionalGeneration.from_pretrained(model_path)\n","processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n","\n","# Test English sentences\n","english_tests = [\n","    \"Hello, how are you doing today?\",\n","    \"The weather is beautiful outside.\",\n","    \"I would like to order a coffee please.\",\n","]\n","\n","print(\"🧪 Testing with Language Forcing\")\n","print(\"=\" * 60)\n","\n","for i, text in enumerate(english_tests, 1):\n","    dummy_audio = np.random.randn(16000 * 3)\n","\n","    input_features = processor(\n","        dummy_audio,\n","        sampling_rate=16000,\n","        return_tensors=\"pt\"\n","    ).input_features\n","\n","    # Force English language during generation\n","    forced_decoder_ids = processor.get_decoder_prompt_ids(\n","        language=\"en\",\n","        task=\"transcribe\"\n","    )\n","\n","    with torch.no_grad():\n","        predicted_ids = model.generate(\n","            input_features,\n","            max_length=225,\n","            forced_decoder_ids=forced_decoder_ids  # Force English output\n","        )\n","\n","    prediction = processor.decode(predicted_ids[0], skip_special_tokens=True)\n","\n","    print(f\"{i}. Expected: '{text}'\")\n","    print(f\"   Got:      '{prediction}'\")\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V1QEA_Nc5Y80","executionInfo":{"status":"ok","timestamp":1761723924294,"user_tz":420,"elapsed":21342,"user":{"displayName":"Abhishek Adhikari","userId":"04717267656706313486"}},"outputId":"a163e81c-a9e8-4990-e4b5-e0595a4e8d97"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["🧪 Testing with Language Forcing\n","============================================================\n","1. Expected: 'Hello, how are you doing today?'\n","   Got:      ' Ssshh!'\n","\n","2. Expected: 'The weather is beautiful outside.'\n","   Got:      ' Ssshh!'\n","\n","3. Expected: 'I would like to order a coffee please.'\n","   Got:      '.'\n","\n"]}]},{"cell_type":"markdown","source":["Model completely forgots english language. LOL"],"metadata":{"id":"mmj2kK9R7gkE"}},{"cell_type":"code","source":[],"metadata":{"id":"Z34brDDN6SZq"},"execution_count":null,"outputs":[]}]}